{% extends "base.html" %}
{% block content %}
<div class="bodyContent">
    <div class="featuresContainerForReal">
        <div class="featuresContainer">
            <h2 class="appPrompt">Set the levels of audio features</h2>
            <p class="promptDescription">Use the sliders to set your desired level for each audio feature. These features are automatically set on each track by Spotify, and are available to help you refine your playlist.</p>
            <form method="post" class="featuresSliders">
                <div class="sliderGroup">
                    <h2 class="featureLabel">Acousticness</h2>
                    <h3 class="featureDescription">A confidence measure of whether the track is acoustic.</h3>
                    <input type="range" min="0" max="100" value="50" step="1" name="acousticness" class="slider">
                </div>
                <div class="sliderGroup">
                    <h2 class="featureLabel">Danceability</h2>
                    <h3 class="featureDescription">How suitable a track is for dancing based on a combination of musical elements including tempo, rhythm stability, beat strength, and overall regularity</h3>
                    <input type="range" min="0" max="100" value="50" step="1" name="danceability" class="slider">
                </div>
                <div class="sliderGroup">
                    <h2 class="featureLabel">Energy</h2>
                    <h3 class="featureDescription">Energetic tracks feel fast, loud, and noisy. For example, death metal has high energy, while a Bach prelude scores low on the scale. Perceptual features contributing to this attribute include dynamic range, perceived loudness, timbre, onset rate, and general entropy</h3>
                    <input type="range" min="0" max="100" value="50" step="1" name="energy" class="slider">
                </div>
                <div class="sliderGroup">
                    <h2 class="featureLabel">Instrumentalness</h2>
                    <h3 class="featureDescription">Predicts whether a track contains no vocals. The closer the instrumentalness is to 100, the greater likelihood the track contains to vocal content</h3>
                    <input type="range" min="0" max="100" value="50" step="1" name="instrumentalness" class="slider">
                </div>
                <div class="sliderGroup">
                    <h2 class="featureLabel">Liveness</h2>
                    <h3 class="featureDescription">Detects the presence of an audience in the recording. Higher liveness values represent an increased probability that the track was performed live</h3>
                    <input type="range" min="0" max="100" value="50" step="1" name="liveness" class="slider">
                </div>
                <div class="sliderGroup">
                    <h2 class="featureLabel">Speechiness</h2>
                    <h3 class="featureDescription">Detects the presence of spoken words in a track. Values above 66 describe tracks that are probably made entirely of words. Values between 33-66 describe tracks that may contain both music and speech, either in sections or layered, including some cases as rap music. Values below 33 most likely represent music and other non-speech-like tracks</h3>
                    <input type="range" min="0" max="100" value="50" step="1" name="speechiness" class="slider">
                </div>
                <div class="sliderGroup">
                    <h2 class="featureLabel">Valence</h2>
                    <h3 class="featureDescription">A measure describing the musical positiveness conveyed by a track. Track with high valuence sound more positive (e.g. happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry)</h3>
                    <input type="range" min="0" max="100" value="50" step="1" name="valence" class="slider">
                </div>

                <input type="submit" value="Submit" class="uiButton featuresSubmit">
            </form>
        </div>
    </div>
</div>
{% endblock %}